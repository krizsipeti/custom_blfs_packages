<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE sect1 PUBLIC "-//OASIS//DTD DocBook XML V4.5//EN"
   "http://www.oasis-open.org/docbook/xml/4.5/docbookx.dtd" [
  <!ENTITY % general-entities SYSTEM "../../general.ent">
  %general-entities;

  <!ENTITY libvirt-download-http "https://gitlab.com/libvirt/libvirt/-/archive/v11.2.0/libvirt-v11.2.0.tar.gz">
  <!ENTITY libvirt-download-ftp  " ">
  <!ENTITY libvirt-md5sum        "3627d2a22e57162885083aecc038e940">
  <!ENTITY libvirt-size          "12.6 MB">
  <!ENTITY libvirt-buildsize     "150 MB">
  <!ENTITY libvirt-time          "1 SBU (using parallelism=4)">
]>

<sect1 id="libvirt" xreflabel="libvirt-&libvirt-version;">
  <?dbhtml filename="libvirt.html"?>


  <title>libvirt-&libvirt-version;</title>

  <indexterm zone="libvirt">
    <primary sortas="a-libvirt">libvirt</primary>
  </indexterm>

  <sect2 role="package">
    <title>Introduction to libvirt</title>

    <para>
      <application>libvirt</application> is a toolkit to manage virtualization platforms, providing a unified API for interacting with various hypervisors, containers, and other virtualization technologies.
    </para>

    <bridgehead renderas="sect3">Package Information</bridgehead>
    <itemizedlist spacing="compact">
      <listitem>
        <para>
          Download (HTTP): <ulink url="&libvirt-download-http;"/>
        </para>
      </listitem>
      <listitem>
        <para>
          Download (FTP): <ulink url="&libvirt-download-ftp;"/>
        </para>
      </listitem>
      <listitem>
        <para>
          Download MD5 sum: &libvirt-md5sum;
        </para>
      </listitem>
      <listitem>
        <para>
          Download size: &libvirt-size;
        </para>
      </listitem>
      <listitem>
        <para>
          Estimated disk space required: &libvirt-buildsize;
        </para>
      </listitem>
      <listitem>
        <para>
          Estimated build time: &libvirt-time;
        </para>
      </listitem>
    </itemizedlist>

    <bridgehead renderas="sect3">libvirt Dependencies</bridgehead>

    <bridgehead renderas="sect4">Required</bridgehead>
    <para role="required">
        <xref linkend="python3"/>, and
        <xref linkend="libnl"/>, and
        <xref linkend="libpcap"/>, and
        <xref linkend="qemu"/>
    </para>
  </sect2>

  <sect2 role="installation">
    <title>Installation of libvirt</title>

    <para>
      Install <application>libvirt</application> by running the
      following commands:
    </para>

<screen><userinput>export QEMU_PACK="$(find ../.. -iname qemu-*.tar.*)"  &amp;&amp;
tar --strip-components=3 -C subprojects/keycodemapdb/ -xf "$QEMU_PACK" $(tar -tvf "$QEMU_PACK" | grep -m1 keycodemapdb | awk -F' ' '{print $NF}') &amp;&amp;
meson setup build --prefix=/usr --buildtype=release -Ddriver_qemu=enabled -Dnss=disabled -Dtests=disabled -Dqemu_group=libvirt-qemu -Dqemu_user=libvirt-qemu &amp;&amp;
ninja -C build</userinput></screen>

    <para>
      This package does not come with a test suite.
    </para>

    <para>
      Now, as the <systemitem class="username">root</systemitem> user:
    </para>

<screen role="root"><userinput>ninja -C build install</userinput></screen>

<screen role="root"><userinput>install -v -m755 -d /etc/libvirt &amp;&amp;
install -v -m755 -d /etc/libvirt &amp;&amp;
install -v -m755 -d /etc/libvirt/hooks &amp;&amp;
install -v -m755 -d /etc/libvirt/nwfilter &amp;&amp;
install -v -m755 -d /etc/libvirt/qemu &amp;&amp;
install -v -m700 -d /etc/libvirt/secrets &amp;&amp;
install -v -m755 -d /etc/libvirt/storage</userinput></screen>

<screen role="root"><userinput>cat &gt; /etc/libvirt/libvirt-admin.conf &lt;&lt; "EOF"
#
# This can be used to setup URI aliases for frequently
# used connection URIs. Aliases may contain only the
# characters  a-Z, 0-9, _, -.
#
# Following the '=' may be any valid libvirt admin connection
# URI, including arbitrary parameters

#uri_aliases = [
#  "admin=libvirtd:///system",
#]

# This specifies the default location the client tries to connect to if no other
# URI is provided by the application

#uri_default = "libvirtd:///system"
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /etc/libvirt/libvirt.conf &lt;&lt; "EOF"
#
# This can be used to setup URI aliases for frequently
# used connection URIs. Aliases may contain only the
# characters  a-Z, 0-9, _, -.
#
# Following the '=' may be any valid libvirt connection
# URI, including arbitrary parameters

#uri_aliases = [
#  "hail=qemu+ssh://root@hail.cloud.example.com/system",
#  "sleet=qemu+ssh://root@sleet.cloud.example.com/system",
#]

#
# These can be used in cases when no URI is supplied by the application
# (@uri_default also prevents probing of the hypervisor driver).
#
#uri_default = "qemu:///system"
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /etc/libvirt/libvirtd.conf &lt;&lt; "EOF"
# Master libvirt daemon configuration file
#

#################################################################
#
# Network connectivity controls
#

# Flag listening for secure TLS connections on the public TCP/IP port.
#
# To enable listening sockets with the 'libvirtd' daemon it's also required to
# pass the '--listen' flag on the commandline of the daemon.
# This is not needed with 'virtproxyd'.
#
# This setting is not required or honoured if using systemd socket
# activation.
#
# It is necessary to setup a CA and issue server certificates before
# using this capability.
#
# This is enabled by default, uncomment this to disable it
#listen_tls = 0

# Listen for unencrypted TCP connections on the public TCP/IP port.
#
# To enable listening sockets with the 'libvirtd' daemon it's also required to
# pass the '--listen' flag on the commandline of the daemon.
# This is not needed with 'virtproxyd'.
#
# This setting is not required or honoured if using systemd socket
# activation.
#
# Using the TCP socket requires SASL authentication by default. Only
# SASL mechanisms which support data encryption are allowed. This is
# DIGEST_MD5 and GSSAPI (Kerberos5)
#
# This is disabled by default, uncomment this to enable it.
#listen_tcp = 1



# Override the port for accepting secure TLS connections
# This can be a port number, or service name
#
# This setting is not required or honoured if using systemd socket
# activation.
#
#tls_port = "16514"

# Override the port for accepting insecure TCP connections
# This can be a port number, or service name
#
# This setting is not required or honoured if using systemd socket
# activation.
#
#tcp_port = "16509"


# Override the default configuration which binds to all network
# interfaces. This can be a numeric IPv4/6 address, or hostname
#
# This setting is not required or honoured if using systemd socket
# activation.
#
# If the libvirtd service is started in parallel with network
# startup (e.g. with systemd), binding to addresses other than
# the wildcards (0.0.0.0/::) might not be available yet.
#
#listen_addr = "192.168.0.1"


#################################################################
#
# UNIX socket access controls
#

# Set the UNIX domain socket group ownership. This can be used to
# allow a 'trusted' set of users access to management capabilities
# without becoming root.
#
# This setting is not required or honoured if using systemd socket
# activation.
#
# This is restricted to 'root' by default.
#unix_sock_group = "libvirt"

# Set the UNIX socket permissions for the R/O socket. This is used
# for monitoring VM status only
#
# This setting is not required or honoured if using systemd socket
# activation.
#
# Default allows any user. If setting group ownership, you may want to
# restrict this too.
#unix_sock_ro_perms = "0777"

# Set the UNIX socket permissions for the R/W socket. This is used
# for full management of VMs
#
# This setting is not required or honoured if using systemd socket
# activation.
#
# Default allows only root. If PolicyKit is enabled on the socket,
# the default will change to allow everyone (eg, 0777)
#
# If not using PolicyKit and setting group ownership for access
# control, then you may want to relax this too.
#unix_sock_rw_perms = "0770"

# Set the UNIX socket permissions for the admin interface socket.
#
# This setting is not required or honoured if using systemd socket
# activation.
#
# Default allows only owner (root), do not change it unless you are
# sure to whom you are exposing the access to.
#unix_sock_admin_perms = "0700"

# Set the name of the directory in which sockets will be found/created.
#
# This setting is not required or honoured if using systemd socket
# activation.
#
#unix_sock_dir = "/run/libvirt"



#################################################################
#
# Authentication.
#
# There are the following choices available:
#
#  - none: do not perform auth checks. If you can connect to the
#          socket you are allowed. This is suitable if there are
#          restrictions on connecting to the socket (eg, UNIX
#          socket permissions), or if there is a lower layer in
#          the network providing auth (eg, TLS/x509 certificates)
#
#  - sasl: use SASL infrastructure. The actual auth scheme is then
#          controlled from /etc/sasl2/libvirt.conf. For the TCP
#          socket only GSSAPI and DIGEST-MD5 mechanisms will be used.
#          For non-TCP or TLS sockets, any scheme is allowed.
#
#  - polkit: use PolicyKit to authenticate. This is only suitable
#            for use on the UNIX sockets. The default policy will
#            require a user to supply their own password to gain
#            full read/write access (aka sudo like), while anyone
#            is allowed read/only access.
#

# Set an authentication scheme for UNIX read-only sockets
#
# By default socket permissions allow anyone to connect
#
# If libvirt was compiled without support for 'polkit', then
# no access control checks are done, but libvirt still only
# allows execution of APIs which don't change state.
#
# If libvirt was compiled with support for 'polkit', then
# the libvirt socket will perform a check with polkit after
# connections. The default policy still allows any local
# user access.
#
# To restrict monitoring of domains you may wish to either
# enable 'sasl' here, or change the polkit policy definition.
auth_unix_ro = "none"

# Set an authentication scheme for UNIX read-write sockets.
#
# If libvirt was compiled without support for 'polkit', then
# the systemd .socket files will use SocketMode=0600 by default
# thus only allowing root user to connect, and 'auth_unix_rw'
# will default to 'none'.
#
# If libvirt was compiled with support for 'polkit', then
# the systemd .socket files will use SocketMode=0666 which
# allows any user to connect and 'auth_unix_rw' will default
# to 'polkit'. If you disable use of 'polkit' here, then it
# is essential to change the systemd SocketMode parameter
# back to 0600, to avoid an insecure configuration.
#
auth_unix_rw = "none"

# Change the authentication scheme for TCP sockets.
#
# If you don't enable SASL, then all TCP traffic is cleartext.
# Don't do this outside of a dev/test scenario. For real world
# use, always enable SASL and use the GSSAPI or DIGEST-MD5
# mechanism in /etc/sasl2/libvirt.conf
#auth_tcp = "sasl"

# Change the authentication scheme for TLS sockets.
#
# TLS sockets already have encryption provided by the TLS
# layer, and limited authentication is done by certificates
#
# It is possible to make use of any SASL authentication
# mechanism as well, by using 'sasl' for this option
#auth_tls = "none"

# Enforce a minimum SSF value for TCP sockets
#
# The default minimum is currently 56 (single-DES) which will
# be raised to 112 in the future.
#
# This option can be used to set values higher than 112
#tcp_min_ssf = 112


# Change the API access control scheme
#
# By default an authenticated user is allowed access
# to all APIs. Access drivers can place restrictions
# on this. By default the 'nop' driver is enabled,
# meaning no access control checks are done once a
# client has authenticated with libvirtd
#
#access_drivers = [ "polkit" ]

#################################################################
#
# TLS x509 certificate configuration
#

# Use of TLS requires that x509 certificates be issued. The default locations
# for the certificate files is as follows:
#
#   /etc/pki/CA/cacert.pem - The CA master certificate
#   /etc/pki/libvirt/servercert.pem - The server certificate signed by cacert.pem
#   /etc/pki/libvirt/private/serverkey.pem - The server private key
#
# It is possible to override the default locations by altering the 'key_file',
# 'cert_file', and 'ca_file' values and uncommenting them below.
#
# NB, overriding the default of one location requires uncommenting and
# possibly additionally overriding the other settings.
#

# Override the default server key file path
#
#key_file = "/etc/pki/libvirt/private/serverkey.pem"

# Override the default server certificate file path
#
#cert_file = "/etc/pki/libvirt/servercert.pem"

# Override the default CA certificate path
#
#ca_file = "/etc/pki/CA/cacert.pem"

# Specify a certificate revocation list.
#
# Defaults to not using a CRL, uncomment to enable it
#crl_file = "/etc/pki/CA/crl.pem"



#################################################################
#
# Authorization controls
#


# Flag to disable verification of our own server certificates
#
# When libvirtd starts it performs some sanity checks against
# its own certificates.
#
# Default is to always run sanity checks. Uncommenting this
# will disable sanity checks which is not a good idea
#tls_no_sanity_certificate = 1

# Flag to disable verification of client certificates
#
# Client certificate verification is the primary authentication mechanism.
# Any client which does not present a certificate signed by the CA
# will be rejected.
#
# Default is to always verify. Uncommenting this will disable
# verification.
#tls_no_verify_certificate = 1


# An access control list of allowed x509 Distinguished Names
# This list may contain wildcards such as
#
#    "C=GB,ST=London,L=London,O=Red Hat,CN=*"
#
# Any * matches any number of consecutive spaces, like a simplified glob(7).
#
# The format of the DN for a particular certificate can be queried
# using:
#
#    virt-pki-query-dn clientcert.pem
#
# NB If this is an empty list, no client can connect, so comment out
# entirely rather than using empty list to disable these checks
#
# By default, no DN's are checked
#tls_allowed_dn_list = ["DN1", "DN2"]


# Override the compile time default TLS priority string. The
# default is usually "NORMAL" unless overridden at build time.
# Only set this is it is desired for libvirt to deviate from
# the global default settings.
#
#tls_priority="NORMAL"


# An access control list of allowed SASL usernames. The format for username
# depends on the SASL authentication mechanism. Kerberos usernames
# look like username@REALM
#
# This list may contain wildcards such as
#
#    "*@EXAMPLE.COM"
#
# See the g_pattern_match function for the format of the wildcards.
#
# https://developer.gnome.org/glib/stable/glib-Glob-style-pattern-matching.html
#
# NB If this is an empty list, no client can connect, so comment out
# entirely rather than using empty list to disable these checks
#
# By default, no Username's are checked
#sasl_allowed_username_list = ["joe@EXAMPLE.COM", "fred@EXAMPLE.COM" ]


#################################################################
#
# Processing controls
#

# The maximum number of concurrent client connections to allow
# over all sockets combined.
#max_clients = 5000

# The maximum length of queue of connections waiting to be
# accepted by the daemon. Note, that some protocols supporting
# retransmission may obey this so that a later reattempt at
# connection succeeds.
#max_queued_clients = 1000

# The maximum length of queue of accepted but not yet
# authenticated clients. The default value is 20. Set this to
# zero to turn this feature off.
#max_anonymous_clients = 20

# The minimum limit sets the number of workers to start up
# initially. If the number of active clients exceeds this,
# then more threads are spawned, up to max_workers limit.
# Typically you'd want max_workers to equal maximum number
# of clients allowed
#min_workers = 5
#max_workers = 20


# The number of priority workers. If all workers from above
# pool are stuck, some calls marked as high priority
# (notably domainDestroy) can be executed in this pool.
#prio_workers = 5

# Limit on concurrent requests from a single client
# connection. To avoid one client monopolizing the server
# this should be a small fraction of the global max_workers
# parameter.
# Setting this too low may cause keepalive timeouts.
#max_client_requests = 5

# Same processing controls, but this time for the admin interface.
# For description of each option, be so kind to scroll few lines
# upwards.

#admin_min_workers = 1
#admin_max_workers = 5
#admin_max_clients = 5
#admin_max_queued_clients = 5
#admin_max_client_requests = 5

#################################################################
#
# Logging controls
#

# Logging level: 4 errors, 3 warnings, 2 information, 1 debug
# basically 1 will log everything possible
#
# WARNING: USE OF THIS IS STRONGLY DISCOURAGED.
#
# WARNING: It outputs too much information to practically read.
# WARNING: The "log_filters" setting is recommended instead.
#
# WARNING: Journald applies rate limiting of messages and so libvirt
# WARNING: will limit "log_level" to only allow values 3 or 4 if
# WARNING: journald is the current output.
#
# WARNING: USE OF THIS IS STRONGLY DISCOURAGED.
#log_level = 3

# Logging filters:
# A filter allows to select a different logging level for a given category
# of logs. The format for a filter is:
#
#    level:match
#
# where 'match' is a string which is matched against the category
# given in the VIR_LOG_INIT() at the top of each libvirt source
# file, e.g., "remote", "qemu", or "util.json". The 'match' in the
# filter matches using shell wildcard syntax (see 'man glob(7)').
# The 'match' is always treated as a substring match. IOW a match
# string 'foo' is equivalent to '*foo*'.
#
# 'level' is the minimal level where matching messages should
#  be logged:
#
#    1: DEBUG
#    2: INFO
#    3: WARNING
#    4: ERROR
#
# Multiple filters can be defined in a single @log_filters, they just need
# to be separated by spaces. Note that libvirt performs "first" match, i.e.
# if there are concurrent filters, the first one that matches will be applied,
# given the order in @log_filters.
#
# A typical need is to capture information from a hypervisor driver,
# public API entrypoints and some of the utility code. Some utility
# code is very verbose and is generally not desired. Taking the QEMU
# hypervisor as an example, a suitable filter string for debugging
# might be to turn off object, json and event logging, but enable the
# rest of the util code:
#
#log_filters="1:qemu 1:libvirt 4:object 4:json 4:event 1:util"

# Logging outputs:
# An output is one of the places to save logging information
# The format for an output can be:
#    level:stderr
#      output goes to stderr
#    level:syslog:name
#      use syslog for the output and use the given name as the ident
#    level:file:file_path
#      output to a file, with the given filepath
#    level:journald
#      output to journald logging system
# In all cases 'level' is the minimal priority, acting as a filter
#    1: DEBUG
#    2: INFO
#    3: WARNING
#    4: ERROR
#
# Multiple outputs can be defined, they just need to be separated by spaces.
# e.g. to log all warnings and errors to syslog under the libvirtd ident:
#log_outputs="3:syslog:libvirtd"


##################################################################
#
# Auditing
#
# This setting allows usage of the auditing subsystem to be altered:
#
#   audit_level == 0  -&gt; disable all auditing
#   audit_level == 1  -&gt; enable auditing, only if enabled on host (default)
#   audit_level == 2  -&gt; enable auditing, and exit if disabled on host
#
#audit_level = 2
#
# If set to 1, then audit messages will also be sent
# via libvirt logging infrastructure. Defaults to 0
#
#audit_logging = 1

###################################################################
# UUID of the host:
# Host UUID is read from one of the sources specified in host_uuid_source.
#
# - 'smbios': fetch the UUID from 'dmidecode -s system-uuid'
# - 'machine-id': fetch the UUID from /etc/machine-id
#
# The host_uuid_source default is 'smbios'. If 'dmidecode' does not provide
# a valid UUID a temporary UUID will be generated.
#
# Another option is to specify host UUID in host_uuid.
#
# Keep the format of the example UUID below. UUID must not have all digits
# be the same.

# NB This default all-zeros UUID will not work. Replace
# it with the output of the 'uuidgen' command and then
# uncomment this entry
#host_uuid = "00000000-0000-0000-0000-000000000000"
#host_uuid_source = "smbios"

###################################################################
# Keepalive protocol:
# This allows libvirtd to detect broken client connections or even
# dead clients.  A keepalive message is sent to a client after
# keepalive_interval seconds of inactivity to check if the client is
# still responding; keepalive_count is a maximum number of keepalive
# messages that are allowed to be sent to the client without getting
# any response before the connection is considered broken.  In other
# words, the connection is automatically closed approximately after
# keepalive_interval * (keepalive_count + 1) seconds since the last
# message received from the client.  If keepalive_interval is set to
# -1, libvirtd will never send keepalive requests; however clients
# can still send them and the daemon will send responses.  When
# keepalive_count is set to 0, connections will be automatically
# closed after keepalive_interval seconds of inactivity without
# sending any keepalive messages.
#
#keepalive_interval = 5
#keepalive_count = 5

#
# These configuration options are no longer used.  There is no way to
# restrict such clients from connecting since they first need to
# connect in order to ask for keepalive.
#
#keepalive_required = 1
#admin_keepalive_required = 1

# Keepalive settings for the admin interface
#admin_keepalive_interval = 5
#admin_keepalive_count = 5

###################################################################
# Open vSwitch:
# This allows to specify a timeout for openvswitch calls made by
# libvirt. The ovs-vsctl utility is used for the configuration and
# its timeout option is set by default to 5 seconds to avoid
# potential infinite waits blocking libvirt.
#
#ovs_timeout = 5
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /etc/libvirt/libxl.conf &lt;&lt; "EOF"
# Master configuration file for the libxl driver.
# All settings described here are optional.  If omitted, sensible
# defaults are used.

# Enable autoballooning of domain0
#
# By default, autoballooning of domain0 is enabled unless its memory
# is already limited with Xen's "dom0_mem=" parameter, in which case
# autoballooning is disabled.  Override the default behavior with the
# autoballoon setting.
#
#autoballoon = 1


# In order to prevent accidentally starting two domains that
# share one writable disk, libvirt offers two approaches for
# locking files: sanlock and virtlockd.  sanlock is an external
# project which libvirt integrates with via the libvirt-lock-sanlock
# package.  virtlockd is a libvirt implementation that is enabled with
# "lockd".  Accepted values are "sanlock" and "lockd".
#
#lock_manager = "lockd"


# Keepalive protocol:
# This allows the libxl driver to detect broken connections to the
# remote libvirtd during peer-to-peer migration.  A keepalive message
# is sent to the daemon after keepalive_interval seconds of inactivity
# to check if the daemon is still responding; keepalive_count is a
# maximum number of keepalive messages that are allowed to be sent to
# the daemon without getting any response before the connection is
# considered broken.  In other words, the connection is automatically
# closed after approximately keepalive_interval * (keepalive_count + 1)
# seconds since the last message was received from the daemon. If
# keepalive_interval is set to -1, the libxl driver will not send
# keepalive requests during peer-to-peer migration; however, the remote
# libvirtd can still send them and source libvirtd will send responses.
# When keepalive_count is set to 0, connections will be automatically
# closed after keepalive_interval seconds of inactivity without sending
# any keepalive messages.
#
#keepalive_interval = 5
#keepalive_count = 5

# Nested HVM default control. In order to use nested HVM feature, this option
# needs to be enabled, in addition to specifying &lt;cpu mode='host-passthrough'&gt;
# in domain configuration. This can be overridden in domain configuration by
# explicitly setting &lt;feature policy='require' name='vmx'/&gt; inside &lt;cpu/&gt;
# element.
# By default it is disabled.
#nested_hvm = 0
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /etc/libvirt/libxl-lockd.conf &lt;&lt; "EOF"
#
# The default lockd behaviour is to acquire locks directly
# against each configured disk file / block device. If the
# application wishes to instead manually manage leases in
# the guest XML, then this parameter can be disabled
#
#auto_disk_leases = 0

#
# Flag to determine whether we allow starting of guests
# which do not have any &lt;lease&gt; elements defined in their
# configuration.
#
# If 'auto_disk_leases' is disabled, this setting defaults
# to enabled, otherwise it defaults to disabled.
#
#require_lease_for_disks = 1


#
# The default lockd behaviour is to use the "direct"
# lockspace, where the locks are acquired against the
# actual file paths associated with the &lt;disk&gt; devices.
#
# Setting a directory here causes lockd to use "indirect"
# lockspace, where a hash of the &lt;disk&gt; file path is
# used to create a file in the lockspace directory. The
# locks are then held on these hash files instead.
#
# This can be useful if the file paths refer to block
# devices which are shared, since /dev fcntl() locks
# don't propagate across hosts. It is also useful if
# the filesystem does not support fcntl() locks.
#
# Typically this directory would be located on a shared
# filesystem visible to all hosts accessing the same
# storage.
#
#file_lockspace_dir = "/var/lib/libvirt/lockd/files"


#
# When using LVM volumes that can be visible across
# multiple, it is desirable to do locking based on
# the unique UUID associated with each volume, instead
# of their paths. Setting this path causes libvirt to
# do UUID based locking for LVM.
#
# Typically this directory would be located on a shared
# filesystem visible to all hosts accessing the same
# storage.
#
#lvm_lockspace_dir = "/var/lib/libvirt/lockd/lvmvolumes"


#
# When using SCSI volumes that can be visible across
# multiple, it is desirable to do locking based on
# the unique UUID associated with each volume, instead
# of their paths. Setting this path causes libvirt to
# do UUID based locking for SCSI.
#
# Typically this directory would be located on a shared
# filesystem visible to all hosts accessing the same
# storage.
#
#scsi_lockspace_dir = "/var/lib/libvirt/lockd/scsivolumes"
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /etc/libvirt/libxl-sanlock.conf &lt;&lt; "EOF"
#
# The default sanlock configuration requires the management
# application to manually define &lt;lease&gt; elements in the
# guest configuration, typically one lease per disk. An
# alternative is to enable "auto disk lease" mode. In this
# usage, libvirt will automatically create a lockspace and
# lease for each fully qualified disk path. This works if
# you are able to ensure stable, unique disk paths across
# all hosts in a network.
#
# Uncomment this to enable automatic lease creation.
#
# NB: the 'host_id' parameter must be set if enabling this
#
#auto_disk_leases = 1

#
# The default location in which lockspaces are created when
# automatic lease creation is enabled. For each unique disk
# path, a file $LEASE_DIR/NNNNNNNNNNNNNN will be created
# where 'NNNNNNNNNNNNNN' is the MD5 hash of the disk path.
#
# If this directory is on local storage, it will only protect
# against a VM being started twice on the same host, or two
# guests on the same host using the same disk path. If the
# directory is on NFS, then it can protect against concurrent
# usage across all hosts which have the share mounted.
#
# Recommendation is to just mount this default location as
# an NFS volume. Uncomment this, if you would prefer the mount
# point to be somewhere else. Moreover, please make sure
# sanlock daemon can access the specified path.
#
#disk_lease_dir = "/var/lib/libvirt/sanlock"

#
# The unique ID for this host.
#
# IMPORTANT: *EVERY* host which can access the filesystem mounted
# at 'disk_lease_dir' *MUST* be given a different host ID.
#
# This parameter has no default and must be manually set if
# 'auto_disk_leases' is enabled
#host_id = 1

#
# Flag to determine whether we allow starting of guests
# which do not have any &lt;lease&gt; elements defined in their
# configuration.
#
# If 'auto_disk_leases' is disabled, this setting defaults
# to enabled, otherwise it defaults to disabled.
#
#require_lease_for_disks = 1

#
# Sanlock is able to kill qemu processes on IO timeout. By its internal
# implementation, the current default is 80 seconds. If you need to adjust
# the value change the following variable. Value of zero means use the
# default sanlock timeout.
#io_timeout = 0

#
# The combination of user and group under which the sanlock
# daemon runs. Libvirt will chown created files (like
# content of disk_lease_dir) to make sure sanlock daemon can
# access them. Accepted values are described in qemu.conf.
#user = "root"
#group = "root"
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /etc/libvirt/lxc.conf &lt;&lt; "EOF"
# Master configuration file for the LXC driver.
# All settings described here are optional - if omitted, sensible
# defaults are used.

# By default, log messages generated by the lxc controller go to the
# container logfile. It is also possible to accumulate log messages
# from all lxc controllers along with libvirtd's log outputs. In this
# case, the lxc controller will honor either LIBVIRT_LOG_OUTPUTS or
# log_outputs from libvirtd.conf.
#
# This is disabled by default, uncomment below to enable it.
#
#log_with_libvirtd = 1


# The default security driver is SELinux. If SELinux is disabled
# on the host, then the security driver will automatically disable
# itself. If you wish to disable LXC SELinux security driver while
# leaving SELinux enabled for the host in general, then set this
# to 'none' instead.
#
#security_driver = "selinux"

# If set to non-zero, then the default security labeling
# will make guests confined. If set to zero, then guests
# will be unconfined by default. Defaults to 0.
#security_default_confined = 1

# If set to non-zero, then attempts to create unconfined
# guests will be blocked. Defaults to 0.
#security_require_confined = 1
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /etc/libvirt/qemu.conf &lt;&lt; "EOF"
# Master configuration file for the QEMU driver.
# All settings described here are optional - if omitted, sensible
# defaults are used.

# Use of TLS requires that x509 certificates be issued. The default is
# to keep them in /etc/pki/qemu. This directory must contain
#
#  ca-cert.pem - the CA master certificate
#  server-cert.pem - the server certificate signed with ca-cert.pem
#  server-key.pem  - the server private key
#
# and optionally may contain
#
#  dh-params.pem - the DH params configuration file
#
# If the directory does not exist, libvirtd will fail to start. If the
# directory doesn't contain the necessary files, QEMU domains will fail
# to start if they are configured to use TLS.
#
# In order to overwrite the default path alter the following. This path
# definition will be used as the default path for other *_tls_x509_cert_dir
# configuration settings if their default path does not exist or is not
# specifically set.
#
#default_tls_x509_cert_dir = "/etc/pki/qemu"


# The default TLS configuration only uses certificates for the server
# allowing the client to verify the server's identity and establish
# an encrypted channel.
#
# It is possible to use x509 certificates for authentication too, by
# issuing an x509 certificate to every client who needs to connect.
#
# Enabling this option will reject any client who does not have a
# certificate signed by the CA in /etc/pki/qemu/ca-cert.pem
#
# The default_tls_x509_cert_dir directory must also contain
#
#  client-cert.pem - the client certificate signed with the ca-cert.pem
#  client-key.pem - the client private key
#
# If this option is supplied it provides the default for the "_verify" option
# of specific TLS users such as vnc, backups, migration, etc. The specific
# users of TLS may override this by setting the specific "_verify" option.
#
# When not supplied the specific TLS users provide their own defaults.
#
#default_tls_x509_verify = 1

#
# Libvirt assumes the server-key.pem file is unencrypted by default.
# To use an encrypted server-key.pem file, the password to decrypt
# the PEM file is required. This can be provided by creating a secret
# object in libvirt and then to uncomment this setting to set the UUID
# of the secret.
#
# NB This default all-zeros UUID will not work. Replace it with the
# output from the UUID for the TLS secret from a 'virsh secret-list'
# command and then uncomment the entry
#
#default_tls_x509_secret_uuid = "00000000-0000-0000-0000-000000000000"


# VNC is configured to listen on 127.0.0.1 by default.
# To make it listen on all public interfaces, uncomment
# this next option.
#
# NB, strong recommendation to enable TLS + x509 certificate
# verification when allowing public access
#
#vnc_listen = "0.0.0.0"

# Enable this option to have VNC served over an automatically created
# unix socket. This prevents unprivileged access from users on the
# host machine, though most VNC clients do not support it.
#
# This will only be enabled for VNC configurations that have listen
# type=address but without any address specified. This setting takes
# preference over vnc_listen.
#
#vnc_auto_unix_socket = 1

# Enable use of TLS encryption on the VNC server. This requires
# a VNC client which supports the VeNCrypt protocol extension.
# Examples include vinagre, virt-viewer, virt-manager and vencrypt
# itself. UltraVNC, RealVNC, TightVNC do not support this
#
# It is necessary to setup CA and issue a server certificate
# before enabling this.
#
#vnc_tls = 1


# In order to override the default TLS certificate location for
# vnc certificates, supply a valid path to the certificate directory.
# If the provided path does not exist, libvirtd will fail to start.
# If the path is not provided, but vnc_tls = 1, then the
# default_tls_x509_cert_dir path will be used.
#
#vnc_tls_x509_cert_dir = "/etc/pki/libvirt-vnc"


# Uncomment and use the following option to override the default secret
# UUID provided in the default_tls_x509_secret_uuid parameter.
#
#vnc_tls_x509_secret_uuid = "00000000-0000-0000-0000-000000000000"


# The default TLS configuration only uses certificates for the server
# allowing the client to verify the server's identity and establish
# an encrypted channel.
#
# It is possible to use x509 certificates for authentication too, by
# issuing an x509 certificate to every client who needs to connect.
#
# Enabling this option will reject any client that does not have a
# certificate (as described in default_tls_x509_verify) signed by the
# CA in the vnc_tls_x509_cert_dir (or default_tls_x509_cert_dir).
#
# If this option is not supplied, it will be set to the value of
# "default_tls_x509_verify". If "default_tls_x509_verify" is not supplied either,
# the default is "0".
#
#vnc_tls_x509_verify = 1


# The default VNC password. Only 8 bytes are significant for
# VNC passwords. This parameter is only used if the per-domain
# XML config does not already provide a password. To allow
# access without passwords, leave this commented out. An empty
# string will still enable passwords, but be rejected by QEMU,
# effectively preventing any use of VNC. Obviously change this
# example here before you set this.
#
#vnc_password = "XYZ12345"


# Enable use of SASL encryption on the VNC server. This requires
# a VNC client which supports the SASL protocol extension.
# Examples include vinagre, virt-viewer and virt-manager
# itself. UltraVNC, RealVNC, TightVNC do not support this
#
# It is necessary to configure /etc/sasl2/qemu.conf to choose
# the desired SASL plugin (eg, GSSPI for Kerberos)
#
#vnc_sasl = 1


# The default SASL configuration file is located in /etc/sasl2/
# When running libvirtd unprivileged, it may be desirable to
# override the configs in this location. Set this parameter to
# point to the directory, and create a qemu.conf in that location
#
#vnc_sasl_dir = "/some/directory/sasl2"


# QEMU implements an extension for providing audio over a VNC connection,
# though if your VNC client does not support it, your only chance for getting
# sound output is through regular audio backends. By default, libvirt will
# disable all QEMU sound backends if using VNC, since they can cause
# permissions issues. Enabling this option will make libvirtd honor the
# QEMU_AUDIO_DRV environment variable when using VNC.
#
#vnc_allow_host_audio = 0



# SPICE is configured to listen on 127.0.0.1 by default.
# To make it listen on all public interfaces, uncomment
# this next option.
#
# NB, strong recommendation to enable TLS + x509 certificate
# verification when allowing public access
#
#spice_listen = "0.0.0.0"


# Enable use of TLS encryption on the SPICE server.
#
# It is necessary to setup CA and issue a server certificate
# before enabling this.
#
#spice_tls = 1


# In order to override the default TLS certificate location for
# spice certificates, supply a valid path to the certificate directory.
# If the provided path does not exist, libvirtd will fail to start.
# If the path is not provided, but spice_tls = 1, then the
# default_tls_x509_cert_dir path will be used.
#
#spice_tls_x509_cert_dir = "/etc/pki/libvirt-spice"


# Enable this option to have SPICE served over an automatically created
# unix socket. This prevents unprivileged access from users on the
# host machine.
#
# This will only be enabled for SPICE configurations that have listen
# type=address but without any address specified. This setting takes
# preference over spice_listen.
#
#spice_auto_unix_socket = 1


# The default SPICE password. This parameter is only used if the
# per-domain XML config does not already provide a password. To
# allow access without passwords, leave this commented out. An
# empty string will still enable passwords, but be rejected by
# QEMU, effectively preventing any use of SPICE. Obviously change
# this example here before you set this.
#
#spice_password = "XYZ12345"


# Enable use of SASL encryption on the SPICE server. This requires
# a SPICE client which supports the SASL protocol extension.
#
# It is necessary to configure /etc/sasl2/qemu.conf to choose
# the desired SASL plugin (eg, GSSPI for Kerberos)
#
#spice_sasl = 1

# The default SASL configuration file is located in /etc/sasl2/
# When running libvirtd unprivileged, it may be desirable to
# override the configs in this location. Set this parameter to
# point to the directory, and create a qemu.conf in that location
#
#spice_sasl_dir = "/some/directory/sasl2"

# Enable use of TLS encryption on the chardev TCP transports.
#
# It is necessary to setup CA and issue a server certificate
# before enabling this.
#
#chardev_tls = 1


# In order to override the default TLS certificate location for character
# device TCP certificates, supply a valid path to the certificate directory.
# If the provided path does not exist, libvirtd will fail to start.
# If the path is not provided, but chardev_tls = 1, then the
# default_tls_x509_cert_dir path will be used.
#
#chardev_tls_x509_cert_dir = "/etc/pki/libvirt-chardev"


# The default TLS configuration only uses certificates for the server
# allowing the client to verify the server's identity and establish
# an encrypted channel.
#
# It is possible to use x509 certificates for authentication too, by
# issuing an x509 certificate to every client who needs to connect.
#
# Enabling this option will reject any client that does not have a
# certificate (as described in default_tls_x509_verify) signed by the
# CA in the chardev_tls_x509_cert_dir (or default_tls_x509_cert_dir).
#
# If this option is not supplied, it will be set to the value of
# "default_tls_x509_verify". If "default_tls_x509_verify" is not supplied either,
# the default is "1".
#
#chardev_tls_x509_verify = 1


# Uncomment and use the following option to override the default secret
# UUID provided in the default_tls_x509_secret_uuid parameter.
#
# NB This default all-zeros UUID will not work. Replace it with the
# output from the UUID for the TLS secret from a 'virsh secret-list'
# command and then uncomment the entry
#
#chardev_tls_x509_secret_uuid = "00000000-0000-0000-0000-000000000000"


# Enable use of TLS encryption for all VxHS network block devices that
# don't specifically disable.
#
# When the VxHS network block device server is set up appropriately,
# x509 certificates are required for authentication between the clients
# (qemu processes) and the remote VxHS server.
#
# It is necessary to setup CA and issue the client certificate before
# enabling this.
#
#vxhs_tls = 1


# In order to override the default TLS certificate location for VxHS
# backed storage, supply a valid path to the certificate directory.
# This is used to authenticate the VxHS block device clients to the VxHS
# server.
#
# If the provided path does not exist, libvirtd will fail to start.
# If the path is not provided, but vxhs_tls = 1, then the
# default_tls_x509_cert_dir path will be used.
#
# VxHS block device clients expect the client certificate and key to be
# present in the certificate directory along with the CA master certificate.
# If using the default environment, default_tls_x509_verify must be configured.
# Since this is only a client the server-key.pem certificate is not needed.
# Thus a VxHS directory must contain the following:
#
#  ca-cert.pem - the CA master certificate
#  client-cert.pem - the client certificate signed with the ca-cert.pem
#  client-key.pem - the client private key
#
#vxhs_tls_x509_cert_dir = "/etc/pki/libvirt-vxhs"


# Uncomment and use the following option to override the default secret
# UUID provided in the default_tls_x509_secret_uuid parameter.
#
# NB This default all-zeros UUID will not work. Replace it with the
# output from the UUID for the TLS secret from a 'virsh secret-list'
# command and then uncomment the entry
#
#vxhs_tls_x509_secret_uuid = "00000000-0000-0000-0000-000000000000"


# Enable use of TLS encryption for all NBD disk devices that don't
# specifically disable it.
#
# When the NBD server is set up appropriately, x509 certificates are required
# for authentication between the client and the remote NBD server.
#
# It is necessary to setup CA and issue the client certificate before
# enabling this.
#
#nbd_tls = 1


# In order to override the default TLS certificate location for NBD
# backed storage, supply a valid path to the certificate directory.
# This is used to authenticate the NBD block device clients to the NBD
# server.
#
# If the provided path does not exist, libvirtd will fail to start.
# If the path is not provided, but nbd_tls = 1, then the
# default_tls_x509_cert_dir path will be used.
#
# NBD block device clients expect the client certificate and key to be
# present in the certificate directory along with the CA certificate.
# Since this is only a client the server-key.pem certificate is not needed.
# Thus a NBD directory must contain the following:
#
#  ca-cert.pem - the CA master certificate
#  client-cert.pem - the client certificate signed with the ca-cert.pem
#  client-key.pem - the client private key
#
#nbd_tls_x509_cert_dir = "/etc/pki/libvirt-nbd"


# Uncomment and use the following option to override the default secret
# UUID provided in the default_tls_x509_secret_uuid parameter.
#
# NB This default all-zeros UUID will not work. Replace it with the
# output from the UUID for the TLS secret from a 'virsh secret-list'
# command and then uncomment the entry
#
#nbd_tls_x509_secret_uuid = "00000000-0000-0000-0000-000000000000"


# In order to override the default TLS certificate location for migration
# certificates, supply a valid path to the certificate directory. If the
# provided path does not exist, libvirtd will fail to start. If the path is
# not provided, but TLS-encrypted migration is requested, then the
# default_tls_x509_cert_dir path will be used. Once/if a default certificate is
# enabled/defined, migration will then be able to use the certificate via
# migration API flags.
#
#migrate_tls_x509_cert_dir = "/etc/pki/libvirt-migrate"


# The default TLS configuration only uses certificates for the server
# allowing the client to verify the server's identity and establish
# an encrypted channel.
#
# It is possible to use x509 certificates for authentication too, by
# issuing an x509 certificate to every client who needs to connect.
#
# Enabling this option will reject any client that does not have a
# certificate (as described in default_tls_x509_verify) signed by the
# CA in the migrate_tls_x509_cert_dir (or default_tls_x509_cert_dir).
#
# If this option is not supplied, it will be set to the value of
# "default_tls_x509_verify". If "default_tls_x509_verify" is not supplied
# either, the default is "1".
#
#migrate_tls_x509_verify = 1


# Uncomment and use the following option to override the default secret
# UUID provided in the default_tls_x509_secret_uuid parameter.
#
# NB This default all-zeros UUID will not work. Replace it with the
# output from the UUID for the TLS secret from a 'virsh secret-list'
# command and then uncomment the entry
#
#migrate_tls_x509_secret_uuid = "00000000-0000-0000-0000-000000000000"


# By default TLS is requested using the VIR_MIGRATE_TLS flag, thus not requested
# automatically. Setting 'migate_tls_force' to "1" will prevent any migration
# which is not using VIR_MIGRATE_TLS to ensure higher level of security in
# deployments with TLS.
#
#migrate_tls_force = 0


# In order to override the default TLS certificate location for backup NBD
# server certificates, supply a valid path to the certificate directory. If the
# provided path does not exist, libvirtd will fail to start. If the path is
# not provided, but TLS-encrypted backup is requested, then the
# default_tls_x509_cert_dir path will be used.
#
#backup_tls_x509_cert_dir = "/etc/pki/libvirt-backup"


# The default TLS configuration only uses certificates for the server
# allowing the client to verify the server's identity and establish
# an encrypted channel.
#
# It is possible to use x509 certificates for authentication too, by
# issuing an x509 certificate to every client who needs to connect.
#
# Enabling this option will reject any client that does not have a
# certificate (as described in default_tls_x509_verify) signed by the
# CA in the backup_tls_x509_cert_dir (or default_tls_x509_cert_dir).
#
# If this option is not supplied, it will be set to the value of
# "default_tls_x509_verify". If "default_tls_x509_verify" is not supplied either,
# the default is "1".
#
#backup_tls_x509_verify = 1


# Uncomment and use the following option to override the default secret
# UUID provided in the default_tls_x509_secret_uuid parameter.
#
# NB This default all-zeros UUID will not work. Replace it with the
# output from the UUID for the TLS secret from a 'virsh secret-list'
# command and then uncomment the entry
#
#backup_tls_x509_secret_uuid = "00000000-0000-0000-0000-000000000000"


# By default, if no graphical front end is configured, libvirt will disable
# QEMU audio output since directly talking to alsa/pulseaudio may not work
# with various security settings. If you know what you're doing, enable
# the setting below and libvirt will passthrough the QEMU_AUDIO_DRV
# environment variable when using nographics.
#
#nographics_allow_host_audio = 1


# Override the port for creating both VNC and SPICE sessions (min).
# This defaults to 5900 and increases for consecutive sessions
# or when ports are occupied, until it hits the maximum.
#
# Minimum must be greater than or equal to 5900 as lower number would
# result into negative vnc display number.
#
# Maximum must be less than 65536, because higher numbers do not make
# sense as a port number.
#
#remote_display_port_min = 5900
#remote_display_port_max = 65535

# VNC WebSocket port policies, same rules apply as with remote display
# ports.  VNC WebSockets use similar display &lt;-&gt; port mappings, with
# the exception being that ports start from 5700 instead of 5900.
#
#remote_websocket_port_min = 5700
#remote_websocket_port_max = 65535

# The default security driver is SELinux. If SELinux is disabled
# on the host, then the security driver will automatically disable
# itself. If you wish to disable QEMU SELinux security driver while
# leaving SELinux enabled for the host in general, then set this
# to 'none' instead. It's also possible to use more than one security
# driver at the same time, for this use a list of names separated by
# comma and delimited by square brackets. For example:
#
#       security_driver = [ "selinux", "apparmor" ]
#
# Notes: The DAC security driver is always enabled; as a result, the
# value of security_driver cannot contain "dac".  The value "none" is
# a special value; security_driver can be set to that value in
# isolation, but it cannot appear in a list of drivers.
#
#security_driver = "selinux"

# If set to non-zero, then the default security labeling
# will make guests confined. If set to zero, then guests
# will be unconfined by default. Defaults to 1.
#security_default_confined = 1

# If set to non-zero, then attempts to create unconfined
# guests will be blocked. Defaults to 0.
#security_require_confined = 1

# The user for QEMU processes run by the system instance. It can be
# specified as a user name or as a user id. The qemu driver will try to
# parse this value first as a name and then, if the name doesn't exist,
# as a user id.
#
# Since a sequence of digits is a valid user name, a leading plus sign
# can be used to ensure that a user id will not be interpreted as a user
# name.
#
# By default libvirt runs VMs as non-root and uses AppArmor profiles
# to provide host protection and VM isolation. While AppArmor
# continues to provide this protection when the VMs are running as
# root, /dev/vhost-net, /dev/vhost-vsock and /dev/vhost-scsi access is
# allowed by default in the AppArmor security policy, so malicious VMs
# running as root would have direct access to this file. If changing this
# to run as root, you may want to remove this access from
# /etc/apparmor.d/abstractions/libvirt-qemu. For more information, see:
# https://launchpad.net/bugs/1815910
# https://www.redhat.com/archives/libvir-list/2019-April/msg00750.html
#
# Some examples of valid values are:
#
#       user = "qemu"   # A user named "qemu"
#       user = "+0"     # Super user (uid=0)
#       user = "100"    # A user named "100" or a user with uid=100
#
#user = "libvirt-qemu"

# The group for QEMU processes run by the system instance. It can be
# specified in a similar way to user.
#group = "kvm"

# Whether libvirt should dynamically change file ownership
# to match the configured user/group above. Defaults to 1.
# Set to 0 to disable file ownership changes.
#dynamic_ownership = 1

# Whether libvirt should remember and restore the original
# ownership over files it is relabeling. Defaults to 1, set
# to 0 to disable the feature.
#remember_owner = 1

# What cgroup controllers to make use of with QEMU guests
#
#  - 'cpu' - use for scheduler tunables
#  - 'devices' - use for device access control
#  - 'memory' - use for memory tunables
#  - 'blkio' - use for block devices I/O tunables
#  - 'cpuset' - use for CPUs and memory nodes
#  - 'cpuacct' - use for CPUs statistics.
#
# NB, even if configured here, they won't be used unless
# the administrator has mounted cgroups, e.g.:
#
#  mkdir /dev/cgroup
#  mount -t cgroup -o devices,cpu,memory,blkio,cpuset none /dev/cgroup
#
# They can be mounted anywhere, and different controllers
# can be mounted in different locations. libvirt will detect
# where they are located.
#
#cgroup_controllers = [ "cpu", "devices", "memory", "blkio", "cpuset", "cpuacct" ]

# This is the basic set of devices allowed / required by
# all virtual machines.
#
# As well as this, any configured block backed disks,
# all sound device, and all PTY devices are allowed.
#
# This will only need setting if newer QEMU suddenly
# wants some device we don't already know about.
#
#cgroup_device_acl = [
#    "/dev/null", "/dev/full", "/dev/zero",
#    "/dev/random", "/dev/urandom",
#    "/dev/ptmx", "/dev/kvm"
#]
#
# RDMA migration requires the following extra files to be added to the list:
#   "/dev/infiniband/rdma_cm",
#   "/dev/infiniband/issm0",
#   "/dev/infiniband/issm1",
#   "/dev/infiniband/umad0",
#   "/dev/infiniband/umad1",
#   "/dev/infiniband/uverbs0"


# The default format for QEMU/KVM guest save images is raw; that is, the
# memory from the domain is dumped out directly to a file.  If you have
# guests with a large amount of memory, however, this can take up quite
# a bit of space.  If you would like to compress the images while they
# are being saved to disk, you can also set "lzop", "gzip", "bzip2", or "xz"
# for save_image_format.  Note that this means you slow down the process of
# saving a domain in order to save disk space; the list above is in descending
# order by performance and ascending order by compression ratio.
#
# save_image_format is used when you use 'virsh save' or 'virsh managedsave'
# at scheduled saving, and it is an error if the specified save_image_format
# is not valid, or the requested compression program can't be found.
#
# dump_image_format is used when you use 'virsh dump' at emergency
# crashdump, and if the specified dump_image_format is not valid, or
# the requested compression program can't be found, this falls
# back to "raw" compression.
#
# snapshot_image_format specifies the compression algorithm of the memory save
# image when an external snapshot of a domain is taken. This does not apply
# on disk image format. It is an error if the specified format isn't valid,
# or the requested compression program can't be found.
#
#save_image_format = "raw"
#dump_image_format = "raw"
#snapshot_image_format = "raw"

# When a domain is configured to be auto-dumped when libvirtd receives a
# watchdog event from qemu guest, libvirtd will save dump files in directory
# specified by auto_dump_path. Default value is /var/lib/libvirt/qemu/dump
#
#auto_dump_path = "/var/lib/libvirt/qemu/dump"

# When a domain is configured to be auto-dumped, enabling this flag
# has the same effect as using the VIR_DUMP_BYPASS_CACHE flag with the
# virDomainCoreDump API.  That is, the system will avoid using the
# file system cache while writing the dump file, but may cause
# slower operation.
#
#auto_dump_bypass_cache = 0

# When a domain is configured to be auto-started, enabling this flag
# has the same effect as using the VIR_DOMAIN_START_BYPASS_CACHE flag
# with the virDomainCreateWithFlags API.  That is, the system will
# avoid using the file system cache when restoring any managed state
# file, but may cause slower operation.
#
#auto_start_bypass_cache = 0

# If provided by the host and a hugetlbfs mount point is configured,
# a guest may request huge page backing.  When this mount point is
# unspecified here, determination of a host mount point in /proc/mounts
# will be attempted.  Specifying an explicit mount overrides detection
# of the same in /proc/mounts.  Setting the mount point to "" will
# disable guest hugepage backing. If desired, multiple mount points can
# be specified at once, separated by comma and enclosed in square
# brackets, for example:
#
#     hugetlbfs_mount = ["/dev/hugepages2M", "/dev/hugepages1G"]
#
# The size of huge page served by specific mount point is determined by
# libvirt at the daemon startup.
#
# NB, within these mount points, guests will create memory backing
# files in a location of $MOUNTPOINT/libvirt/qemu
#
#hugetlbfs_mount = "/dev/hugepages"


# Path to the setuid helper for creating tap devices.  This executable
# is used to create &lt;source type='bridge'&gt; interfaces when libvirtd is
# running unprivileged.  libvirt invokes the helper directly, instead
# of using "-netdev bridge", for security reasons.
# If this is not an absolute path, the program will be searched for
# in $PATH as well as a few additional directories.
#bridge_helper = "qemu-bridge-helper"


# If enabled, libvirt will have QEMU set its process name to
# "qemu:VM_NAME", where VM_NAME is the name of the VM. The QEMU
# process will appear as "qemu:VM_NAME" in process listings and
# other system monitoring tools. By default, QEMU does not set
# its process title, so the complete QEMU command (emulator and
# its arguments) appear in process listings.
#
#set_process_name = 1


# If max_processes is set to a positive integer, libvirt will use
# it to set the maximum number of processes that can be run by qemu
# user. This can be used to override default value set by host OS.
# The same applies to max_files which sets the limit on the maximum
# number of opened files.
#
#max_processes = 0
#max_files = 0

# If max_threads_per_process is set to a positive integer, libvirt
# will use it to set the maximum number of threads that can be
# created by a qemu process. Some VM configurations can result in
# qemu processes with tens of thousands of threads. systemd-based
# systems typically limit the number of threads per process to
# 16k. max_threads_per_process can be used to override default
# limits in the host OS.
#
#max_threads_per_process = 0

# If max_core is set to a non-zero integer, then QEMU will be
# permitted to create core dumps when it crashes, provided its
# RAM size is smaller than the limit set.
#
# Be warned that the core dump will include a full copy of the
# guest RAM, if the 'dump_guest_core' setting has been enabled,
# or if the guest XML contains
#
#   &lt;memory dumpcore="on"&gt;...guest ram...&lt;/memory&gt;
#
# If guest RAM is to be included, ensure the max_core limit
# is set to at least the size of the largest expected guest
# plus another 1GB for any QEMU host side memory mappings.
#
# As a special case it can be set to the string "unlimited" to
# to allow arbitrarily sized core dumps.
#
# By default the core dump size is set to 0 disabling all dumps
#
# Size is a positive integer specifying bytes or the
# string "unlimited"
#
#max_core = "unlimited"

# Determine if guest RAM is included in QEMU core dumps. By
# default guest RAM will be excluded if a new enough QEMU is
# present. Setting this to '1' will force guest RAM to always
# be included in QEMU core dumps.
#
# This setting will be ignored if the guest XML has set the
# dumpcore attribute on the &lt;memory&gt; element.
#
#dump_guest_core = 1

# mac_filter enables MAC addressed based filtering on bridge ports.
# This currently requires ebtables to be installed.
#
#mac_filter = 1


# By default, PCI devices below non-ACS switch are not allowed to be assigned
# to guests. By setting relaxed_acs_check to 1 such devices will be allowed to
# be assigned to guests.
#
#relaxed_acs_check = 1


# In order to prevent accidentally starting two domains that
# share one writable disk, libvirt offers two approaches for
# locking files. The first one is sanlock, the other one,
# virtlockd, is then our own implementation. Accepted values
# are "sanlock" and "lockd".
#
#lock_manager = "lockd"


# Set limit of maximum APIs queued on one domain. All other APIs
# over this threshold will fail on acquiring job lock. Specially,
# setting to zero turns this feature off.
# Note, that job lock is per domain.
#
#max_queued = 0

###################################################################
# Keepalive protocol:
# This allows qemu driver to detect broken connections to remote
# libvirtd during peer-to-peer migration.  A keepalive message is
# sent to the daemon after keepalive_interval seconds of inactivity
# to check if the daemon is still responding; keepalive_count is a
# maximum number of keepalive messages that are allowed to be sent
# to the daemon without getting any response before the connection
# is considered broken.  In other words, the connection is
# automatically closed approximately after
# keepalive_interval * (keepalive_count + 1) seconds since the last
# message received from the daemon.  If keepalive_interval is set to
# -1, qemu driver will not send keepalive requests during
# peer-to-peer migration; however, the remote libvirtd can still
# send them and source libvirtd will send responses.  When
# keepalive_count is set to 0, connections will be automatically
# closed after keepalive_interval seconds of inactivity without
# sending any keepalive messages.
#
#keepalive_interval = 5
#keepalive_count = 5



# Use seccomp syscall filtering sandbox in QEMU.
# 1 == filter enabled, 0 == filter disabled
#
# Unless this option is disabled, QEMU will be run with
# a seccomp filter that stops it from executing certain
# syscalls.
#
#seccomp_sandbox = 1


# Override the listen address for all incoming migrations. Defaults to
# 0.0.0.0, or :: if both host and qemu are capable of IPv6.
#migration_address = "0.0.0.0"


# The default hostname or IP address which will be used by a migration
# source for transferring migration data to this host.  The migration
# source has to be able to resolve this hostname and connect to it so
# setting "localhost" will not work.  By default, the host's configured
# hostname is used.
#migration_host = "host.example.com"


# Override the port range used for incoming migrations.
#
# Minimum must be greater than 0, however when QEMU is not running as root,
# setting the minimum to be lower than 1024 will not work.
#
# Maximum must not be greater than 65535.
#
#migration_port_min = 49152
#migration_port_max = 49215



# Timestamp QEMU's log messages (if QEMU supports it)
#
# Defaults to 1.
#
#log_timestamp = 0


# Location of master nvram file
#
# This configuration option is obsolete. Libvirt will follow the
# QEMU firmware metadata specification to automatically locate
# firmware images. See docs/interop/firmware.json in the QEMU
# source tree. These metadata files are distributed alongside any
# firmware images intended for use with QEMU.
#
# NOTE: if ANY firmware metadata files are detected, this setting
# will be COMPLETELY IGNORED.
#
# ------------------------------------------
#
# When a domain is configured to use UEFI instead of standard
# BIOS it may use a separate storage for UEFI variables. If
# that's the case libvirt creates the variable store per domain
# using this master file as image. Each UEFI firmware can,
# however, have different variables store. Therefore the nvram is
# a list of strings when a single item is in form of:
#   ${PATH_TO_UEFI_FW}:${PATH_TO_UEFI_VARS}.
# Later, when libvirt creates per domain variable store, this list is
# searched for the master image. The UEFI firmware can be called
# differently for different guest architectures. For instance, it's OVMF
# for x86_64 and i686, but it's AAVMF for aarch64. The libvirt default
# follows this scheme.
#nvram = [
#   "/usr/share/OVMF/OVMF_CODE.fd:/usr/share/OVMF/OVMF_VARS.fd",
#   "/usr/share/OVMF/OVMF_CODE.secboot.fd:/usr/share/OVMF/OVMF_VARS.fd",
#   "/usr/share/AAVMF/AAVMF_CODE.fd:/usr/share/AAVMF/AAVMF_VARS.fd",
#   "/usr/share/AAVMF/AAVMF32_CODE.fd:/usr/share/AAVMF/AAVMF32_VARS.fd",
#   "/usr/share/OVMF/OVMF_CODE.ms.fd:/usr/share/OVMF/OVMF_VARS.ms.fd"
#]

# The backend to use for handling stdout/stderr output from
# QEMU processes.
#
#  'file': QEMU writes directly to a plain file. This is the
#          historical default, but allows QEMU to inflict a
#          denial of service attack on the host by exhausting
#          filesystem space
#
#  'logd': QEMU writes to a pipe provided by virtlogd daemon.
#          This is the current default, providing protection
#          against denial of service by performing log file
#          rollover when a size limit is hit.
#
#stdio_handler = "logd"

# QEMU gluster libgfapi log level, debug levels are 0-9, with 9 being the
# most verbose, and 0 representing no debugging output.
#
# The current logging levels defined in the gluster GFAPI are:
#
#    0 - None
#    1 - Emergency
#    2 - Alert
#    3 - Critical
#    4 - Error
#    5 - Warning
#    6 - Notice
#    7 - Info
#    8 - Debug
#    9 - Trace
#
# Defaults to 4
#
#gluster_debug_level = 9

# virtiofsd debug
#
# Whether to enable the debugging output of the virtiofsd daemon.
# Possible values are 0 or 1. Disabled by default.
#
#virtiofsd_debug = 1

# To enhance security, QEMU driver is capable of creating private namespaces
# for each domain started. Well, so far only "mount" namespace is supported. If
# enabled it means qemu process is unable to see all the devices on the system,
# only those configured for the domain in question. Libvirt then manages
# devices entries throughout the domain lifetime. This namespace is turned on
# by default.
#namespaces = [ "mount" ]

# This directory is used for memoryBacking source if configured as file.
# NOTE: big files will be stored here
#memory_backing_dir = "/var/lib/libvirt/qemu/ram"

# Path to the SCSI persistent reservations helper. This helper is
# used whenever reservations are enabled for SCSI LUN devices.
# If this is not an absolute path, the program will be searched for
# in $PATH as well as a few additional directories.
#pr_helper = "qemu-pr-helper"

# Path to the SLIRP networking helper.
#slirp_helper = "/usr/bin/slirp-helper"

# Path to the dbus-daemon
# If this is not an absolute path, the program will be searched for
# in $PATH.
#dbus_daemon = "dbus-daemon"

# User for the swtpm TPM Emulator
#
# Default is 'swtpm' as established by the swtpm-tools package.
#
# In the past this was 'tss' and that still would be the built-in default
# if nothing was configured here, but the 'tss' user also has TPM device
# access in the host which isn't needed for swtpm.
#
swtpm_user = "swtpm"
swtpm_group = "swtpm"

# For debugging and testing purposes it's sometimes useful to be able to disable
# libvirt behaviour based on the capabilities of the qemu process. This option
# allows to do so. DO _NOT_ use in production and beaware that the behaviour
# may change across versions.
#
#capability_filters = [ "capname" ]

# 'deprecation_behavior' setting controls how the qemu process behaves towards
# deprecated commands and arguments used by libvirt.
#
# This setting is meant for developers and CI efforts to make it obvious when
# libvirt relies on fields which are deprecated so that it can be fixes as soon
# as possible.
#
# Possible options are:
# "none"   - (default) qemu is supposed to accept and output deprecated fields
#            and commands
# "omit"   - qemu is instructed to omit deprecated fields on output, behaviour
#            towards fields and commands from qemu is not changed
# "reject" - qemu is instructed to report an error if a deprecated command or
#            field is used by libvirtd
# "crash"  - qemu crashes when an deprecated command or field is used by libvirtd
#
# For both "reject" and "crash" qemu is instructed to omit any deprecated fields
# on output.
#
# The "reject" option is less harsh towards the VMs but some code paths ignore
# errors reported by qemu and thus it may not be obvious that a deprecated
# command/field was used, thus it's suggested to use the "crash" option instead.
#
# In cases when qemu doesn't support configuring the behaviour this setting is
# silently ignored to allow testing older qemu versions without having to
# reconfigure libvirtd.
#
# DO NOT use in production.
#
#deprecation_behavior = "none"

# If this is set then QEMU and its threads will run in a separate scheduling
# group meaning no other process will share Hyper Threads of a single core with
# QEMU. Each QEMU has its own group.
#
# Possible options are:
# "none"     - (default) neither QEMU or any of its helper processes are placed
#              into separate scheduling group
# "vcpus"    - only QEMU vCPU threads are placed into a separate scheduling group,
#              emulator threads and helper processes remain outside of the group
# "emulator" - only QEMU and its threads (emulator + vCPUs) are placed into
#              separate scheduling group, helper processes remain outside of
#              the group
# "full"    -  both QEMU and its helper processes are placed into separate
#              scheduling group
#sched_core = "none"

# Using nbdkit to access remote disk sources
#
# If this is set then libvirt will use nbdkit to access remote disk sources
# when available. nbdkit will export an NBD share to QEMU rather than having
# QEMU attempt to access the remote server directly.
#
# Possible values are 0 or 1. Default value is 0. Please
# note that the default might change in future releases.
#
#storage_use_nbdkit = 0
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /etc/libvirt/qemu-lockd.conf &lt;&lt; "EOF"
#
# The default lockd behaviour is to acquire locks directly
# against each configured disk file / block device. If the
# application wishes to instead manually manage leases in
# the guest XML, then this parameter can be disabled
#
#auto_disk_leases = 0

#
# Flag to determine whether we allow starting of guests
# which do not have any &lt;lease&gt; elements defined in their
# configuration.
#
# If 'auto_disk_leases' is disabled, this setting defaults
# to enabled, otherwise it defaults to disabled.
#
#require_lease_for_disks = 1


#
# The default lockd behaviour is to use the "direct"
# lockspace, where the locks are acquired against the
# actual file paths associated with the &lt;disk&gt; devices.
#
# Setting a directory here causes lockd to use "indirect"
# lockspace, where a hash of the &lt;disk&gt; file path is
# used to create a file in the lockspace directory. The
# locks are then held on these hash files instead.
#
# This can be useful if the file paths refer to block
# devices which are shared, since /dev fcntl() locks
# don't propagate across hosts. It is also useful if
# the filesystem does not support fcntl() locks.
#
# Typically this directory would be located on a shared
# filesystem visible to all hosts accessing the same
# storage.
#
#file_lockspace_dir = "/var/lib/libvirt/lockd/files"


#
# When using LVM volumes that can be visible across
# multiple, it is desirable to do locking based on
# the unique UUID associated with each volume, instead
# of their paths. Setting this path causes libvirt to
# do UUID based locking for LVM.
#
# Typically this directory would be located on a shared
# filesystem visible to all hosts accessing the same
# storage.
#
#lvm_lockspace_dir = "/var/lib/libvirt/lockd/lvmvolumes"


#
# When using SCSI volumes that can be visible across
# multiple, it is desirable to do locking based on
# the unique UUID associated with each volume, instead
# of their paths. Setting this path causes libvirt to
# do UUID based locking for SCSI.
#
# Typically this directory would be located on a shared
# filesystem visible to all hosts accessing the same
# storage.
#
#scsi_lockspace_dir = "/var/lib/libvirt/lockd/scsivolumes"
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /etc/libvirt/qemu-sanlock.conf &lt;&lt; "EOF"
#
# The default sanlock configuration requires the management
# application to manually define &lt;lease&gt; elements in the
# guest configuration, typically one lease per disk. An
# alternative is to enable "auto disk lease" mode. In this
# usage, libvirt will automatically create a lockspace and
# lease for each fully qualified disk path. This works if
# you are able to ensure stable, unique disk paths across
# all hosts in a network.
#
# Uncomment this to enable automatic lease creation.
#
# NB: the 'host_id' parameter must be set if enabling this
#
#auto_disk_leases = 1

#
# The default location in which lockspaces are created when
# automatic lease creation is enabled. For each unique disk
# path, a file $LEASE_DIR/NNNNNNNNNNNNNN will be created
# where 'NNNNNNNNNNNNNN' is the MD5 hash of the disk path.
#
# If this directory is on local storage, it will only protect
# against a VM being started twice on the same host, or two
# guests on the same host using the same disk path. If the
# directory is on NFS, then it can protect against concurrent
# usage across all hosts which have the share mounted.
#
# Recommendation is to just mount this default location as
# an NFS volume. Uncomment this, if you would prefer the mount
# point to be somewhere else. Moreover, please make sure
# sanlock daemon can access the specified path.
#
#disk_lease_dir = "/var/lib/libvirt/sanlock"

#
# The unique ID for this host.
#
# IMPORTANT: *EVERY* host which can access the filesystem mounted
# at 'disk_lease_dir' *MUST* be given a different host ID.
#
# This parameter has no default and must be manually set if
# 'auto_disk_leases' is enabled
#host_id = 1

#
# Flag to determine whether we allow starting of guests
# which do not have any &lt;lease&gt; elements defined in their
# configuration.
#
# If 'auto_disk_leases' is disabled, this setting defaults
# to enabled, otherwise it defaults to disabled.
#
#require_lease_for_disks = 1

#
# Sanlock is able to kill qemu processes on IO timeout. By its internal
# implementation, the current default is 80 seconds. If you need to adjust
# the value change the following variable. Value of zero means use the
# default sanlock timeout.
#io_timeout = 0

#
# The combination of user and group under which the sanlock
# daemon runs. Libvirt will chown created files (like
# content of disk_lease_dir) to make sure sanlock daemon can
# access them. Accepted values are described in qemu.conf.
#user = "root"
#group = "root"
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /etc/libvirt/virtlockd.conf &lt;&lt; "EOF"
# Master virtlockd daemon configuration file
#

#################################################################
#
# Logging controls
#

# Logging level: 4 errors, 3 warnings, 2 information, 1 debug
# basically 1 will log everything possible
#
# WARNING: USE OF THIS IS STRONGLY DISCOURAGED.
#
# WARNING: It outputs too much information to practically read.
# WARNING: The "log_filters" setting is recommended instead.
#
# WARNING: Journald applies rate limiting of messages and so libvirt
# WARNING: will limit "log_level" to only allow values 3 or 4 if
# WARNING: journald is the current output.
#
# WARNING: USE OF THIS IS STRONGLY DISCOURAGED.
#log_level = 3

# Logging filters:
# A filter allows to select a different logging level for a given category
# of logs. The format for a filter is:
#
#    level:match
#
# where 'match' is a string which is matched against the category
# given in the VIR_LOG_INIT() at the top of each libvirt source
# file, e.g., "remote", "qemu", or "util.json". The 'match' in the
# filter matches using shell wildcard syntax (see 'man glob(7)').
# The 'match' is always treated as a substring match. IOW a match
# string 'foo' is equivalent to '*foo*'.
#
# 'level' is the minimal level where matching messages should
#  be logged:
#
#    1: DEBUG
#    2: INFO
#    3: WARNING
#    4: ERROR
#
# Multiple filters can be defined in a single @log_filters, they just need
# to be separated by spaces. Note that libvirt performs "first" match, i.e.
# if there are concurrent filters, the first one that matches will be applied,
# given the order in @log_filters.
#
# For the virtlockd daemon, a typical need is to capture information
# from the locking code and some of the utility code. Some utility
# code is very verbose and is generally not desired. A suitable filter
# string for debugging might be to turn off object, json and event logging,
# but enable the rest of the util and the locking code:
#
#log_filters="1:locking 4:object 4:json 4:event 1:util"

# Logging outputs:
# An output is one of the places to save logging information
# The format for an output can be:
#    level:stderr
#      output goes to stderr
#    level:syslog:name
#      use syslog for the output and use the given name as the ident
#    level:file:file_path
#      output to a file, with the given filepath
#    level:journald
#      output to journald logging system
# In all cases 'level' is the minimal priority, acting as a filter
#    1: DEBUG
#    2: INFO
#    3: WARNING
#    4: ERROR
#
# Multiple outputs can be defined, they just need to be separated by spaces.
# e.g. to log all warnings and errors to syslog under the virtlockd ident:
#log_outputs="3:syslog:virtlockd"
#

# The maximum number of concurrent client connections to allow
# on primary socket
# Each running virtual machine will require one open connection
# to virtlockd. So 'max_clients' will affect how many VMs can
# be run on a host
#max_clients = 1024

# The maximum number of concurrent client connections to allow
# on administrative socket
#admin_max_clients = 5
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /etc/libvirt/virtlogd.conf &lt;&lt; "EOF"
# Master virtlogd daemon configuration file
#

#################################################################
#
# Logging controls
#

# Logging level: 4 errors, 3 warnings, 2 information, 1 debug
# basically 1 will log everything possible
#
# WARNING: USE OF THIS IS STRONGLY DISCOURAGED.
#
# WARNING: It outputs too much information to practically read.
# WARNING: The "log_filters" setting is recommended instead.
#
# WARNING: Journald applies rate limiting of messages and so libvirt
# WARNING: will limit "log_level" to only allow values 3 or 4 if
# WARNING: journald is the current output.
#
# WARNING: USE OF THIS IS STRONGLY DISCOURAGED.
#log_level = 3

# Logging filters:
# A filter allows to select a different logging level for a given category
# of logs. The format for a filter is:
#
#    level:match
#
# where 'match' is a string which is matched against the category
# given in the VIR_LOG_INIT() at the top of each libvirt source
# file, e.g., "remote", "qemu", or "util.json". The 'match' in the
# filter matches using shell wildcard syntax (see 'man glob(7)').
# The 'match' is always treated as a substring match. IOW a match
# string 'foo' is equivalent to '*foo*'.
#
# 'level' is the minimal level where matching messages should
#  be logged:
#
#    1: DEBUG
#    2: INFO
#    3: WARNING
#    4: ERROR
#
# Multiple filters can be defined in a single @log_filters, they just need
# to be separated by spaces. Note that libvirt performs "first" match, i.e.
# if there are concurrent filters, the first one that matches will be applied,
# given the order in @log_filters.
#
# For the virtlogd daemon, a typical need is to capture information
# from the logging code and some of the utility code. Some utility
# code is very verbose and is generally not desired. A suitable filter
# string for debugging might be to turn off object, json and event logging,
# but enable the rest of the util and the logging code:
#
#log_filters="1:logging 4:object 4:json 4:event 1:util"

# Logging outputs:
# An output is one of the places to save logging information
# The format for an output can be:
#    level:stderr
#      output goes to stderr
#    level:syslog:name
#      use syslog for the output and use the given name as the ident
#    level:file:file_path
#      output to a file, with the given filepath
#    level:journald
#      output to journald logging system
# In all cases 'level' is the minimal priority, acting as a filter
#    1: DEBUG
#    2: INFO
#    3: WARNING
#    4: ERROR
#
# Multiple outputs can be defined, they just need to be separated by spaces.
# e.g. to log all warnings and errors to syslog under the virtlogd ident:
#log_outputs="3:syslog:virtlogd"
#

# The maximum number of concurrent client connections to allow
# on primary socket
#max_clients = 1024

# The maximum number of concurrent client connections to allow
# on administrative socket
#admin_max_clients = 5

# Maximum file size before rolling over. Defaults to 2 MB
#
# Setting max_size to zero will disable rollover entirely.
# NOTE: disabling rollover exposes the host filesystem to
# denial of service from a malicious guest.
#
# Beware that a logrotate config file might be installed too,
# to handle cases where virtlogd is disabled. To ensure that
# the logrotate config is a no-op when virtlogd is running,
# make sure that max_size here is smaller than size listed
# in the logrotate config.
#max_size = 2097152

# Maximum number of backup files to keep. Defaults to 3,
# not including the primary active file
#max_backups = 3

# Maximum age for log files to live after the last modification.
# Defaults to 0, which means "forever".
#
# WARNING: since virtlogd has no way to differentiate which files it used to
# manage, the garbage collection mechanism will collect ALL files, once its age
# reach max_age_days. Use only if you know what you mean.
#max_age_days = 0

# Root of all logs managed by virtlogd. Used to GC logs from obsolete machines.
#
# WARNING: all files under this location potentially can be GC-ed. See the
# warning for max_age_days.
#log_root = "/var/log/libvirt"
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/virtlogd.service &lt;&lt; "EOF"
[Unit]
Description=libvirt logging daemon
Documentation=man:virtlogd(8)
Documentation=https://libvirt.org/
BindsTo=virtlogd.socket
Wants=virtlogd-admin.socket
After=virtlogd.socket
After=virtlogd-admin.socket

[Service]
Type=notify
Environment=VIRTLOGD_ARGS=
EnvironmentFile=-/etc/default/virtlogd
ExecStart=/usr/sbin/virtlogd $VIRTLOGD_ARGS
ExecReload=/bin/kill -USR1 $MAINPID
CapabilityBoundingSet=~CAP_AUDIT_CONTROL
CapabilityBoundingSet=~CAP_AUDIT_READ
CapabilityBoundingSet=~CAP_AUDIT_WRITE
CapabilityBoundingSet=~CAP_BLOCK_SUSPEND
CapabilityBoundingSet=~CAP_CHOWN
# Mgmt app/user might have pre-created log files that we're
# told to open and write to, or be storing them in otherwise
# inaccessible locations like $HOME. So we need to ignore
# DAC permission checks.
#CapabilityBoundingSet=~CAP_DAC_OVERRIDE
#CapabilityBoundingSet=~CAP_DAC_READ_SEARCH
CapabilityBoundingSet=~CAP_FOWNER
CapabilityBoundingSet=~CAP_FSETID
CapabilityBoundingSet=~CAP_IPC_LOCK
CapabilityBoundingSet=~CAP_IPC_OWNER
CapabilityBoundingSet=~CAP_KILL
CapabilityBoundingSet=~CAP_LEASE
CapabilityBoundingSet=~CAP_LINUX_IMMUTABLE
CapabilityBoundingSet=~CAP_MAC_ADMIN
CapabilityBoundingSet=~CAP_MAC_OVERRIDE
CapabilityBoundingSet=~CAP_MKNOD
CapabilityBoundingSet=~CAP_NET_ADMIN
CapabilityBoundingSet=~CAP_NET_BIND_SERVICE
CapabilityBoundingSet=~CAP_NET_BROADCAST
CapabilityBoundingSet=~CAP_NET_RAW
CapabilityBoundingSet=~CAP_SETFCAP
CapabilityBoundingSet=~CAP_SETPCAP
CapabilityBoundingSet=~CAP_SETGID
CapabilityBoundingSet=~CAP_SETUID
CapabilityBoundingSet=~CAP_SYSLOG
CapabilityBoundingSet=~CAP_SYS_ADMIN
CapabilityBoundingSet=~CAP_SYS_BOOT
CapabilityBoundingSet=~CAP_SYS_CHROOT
CapabilityBoundingSet=~CAP_SYS_MODULE
CapabilityBoundingSet=~CAP_SYS_NICE
CapabilityBoundingSet=~CAP_SYS_PACCT
CapabilityBoundingSet=~CAP_SYS_PTRACE
CapabilityBoundingSet=~CAP_SYS_RAWIO
CapabilityBoundingSet=~CAP_SYS_RESOURCE
CapabilityBoundingSet=~CAP_SYS_TIME
CapabilityBoundingSet=~CAP_SYS_TTY_CONFIG
CapabilityBoundingSet=~CAP_WAKE_ALARM
LockPersonality=true
MemoryDenyWriteExecute=true
# Cannot enable this as it prevents transitioning to
# the confined SELinux virtlogd_t domain on execve
# unless we modify the policy to allow this.
#NoNewPrivileges=true
PrivateDevices=true
PrivateMounts=true
PrivateNetwork=true
# XXX someone could configure QEMU to log a serial port to an
# arbitrary directory, including /tmp, even if this is ill-advised
#PrivateTmp=true
# Not until oldest build target has systemd &gt;= v245
#ProtectClock=true
ProtectControlGroups=true
# Not until oldest build target has systemd &gt;= v241
#ProtectHostname=true
# Not until oldest build target has systemd &gt;= v244
#ProtectKernelLogs=true
ProtectKernelModules=true
ProtectKernelTunables=true
# Not until oldest build target has systemd &gt;= v247
#ProtectProc=invisible
ProtectSystem=full
RestrictAddressFamilies=AF_UNIX
RestrictNamespaces=~cgroup
RestrictNamespaces=~ipc
RestrictNamespaces=~mnt
RestrictNamespaces=~net
RestrictNamespaces=~pid
RestrictNamespaces=~user
RestrictNamespaces=~uts
RestrictRealtime=true
RestrictSUIDSGID=true
SystemCallArchitectures=native
SystemCallFilter=~@clock
SystemCallFilter=~@debug
SystemCallFilter=~@module
SystemCallFilter=~@mount
SystemCallFilter=~@raw-io
SystemCallFilter=~@reboot
SystemCallFilter=~@swap
SystemCallFilter=~@privileged
# Unfortunately we link to libnuma via libvirt.so which
# has a constructor that runs unconditionally that invokes
# set_mempolicy()
#SystemCallFilter=~@resources
SystemCallFilter=~@cpu-emulation
SystemCallFilter=~@obsolete
UMask=077
# Losing this daemon is a really bad thing that will
# cause the machine to be fenced (rebooted), so make
# sure we discourage OOM killer
OOMScoreAdjust=-900
# Raise hard limits to match behaviour of systemd &gt;= 240.
# During startup, daemon will set soft limit to match hard limit
# per systemd recommendations
LimitNOFILE=1024:524288

[Install]
WantedBy=multi-user.target
Also=virtlogd.socket
Also=virtlogd-admin.socket
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/virtlockd.service &lt;&lt; "EOF"
[Unit]
Description=libvirt locking daemon
Documentation=man:virtlockd(8)
Documentation=https://libvirt.org/
BindsTo=virtlockd.socket
Wants=virtlockd-admin.socket
After=virtlockd.socket
After=virtlockd-admin.socket

[Service]
Type=notify
Environment=VIRTLOCKD_ARGS=
EnvironmentFile=-/etc/default/virtlockd
ExecStart=/usr/sbin/virtlockd $VIRTLOCKD_ARGS
ExecReload=/bin/kill -USR1 $MAINPID
# Losing this daemon is a really bad thing that will
# cause the machine to be fenced (rebooted), so make
# sure we discourage OOM killer
OOMScoreAdjust=-900
# Raise hard limits to match behaviour of systemd &gt;= 240.
# During startup, daemon will set soft limit to match hard limit
# per systemd recommendations
LimitNOFILE=1024:524288

[Install]
WantedBy=multi-user.target
Also=virtlockd.socket
Also=virtlockd-admin.socket
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/libvirtd-tls.socket &lt;&lt; "EOF"
[Unit]
Description=libvirt legacy monolithic daemon TLS IP socket
BindsTo=libvirtd.socket
After=libvirtd.socket

[Socket]
ListenStream=16514
Service=libvirtd.service

[Install]
WantedBy=sockets.target
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/libvirtd-ro.socket &lt;&lt; "EOF"
[Unit]
Description=libvirt legacy monolithic daemon read-only socket
BindsTo=libvirtd.socket
After=libvirtd.socket

[Socket]
ListenStream=/run/libvirt/libvirt-sock-ro
Service=libvirtd.service
SocketMode=0666
RemoveOnStop=yes

[Install]
WantedBy=sockets.target
Also=libvirtd.socket
Also=libvirtd-admin.socket
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/libvirtd.socket &lt;&lt; "EOF"
[Unit]
Description=libvirt legacy monolithic daemon socket

[Socket]
ListenStream=/run/libvirt/libvirt-sock
Service=libvirtd.service
SocketMode=0660
SocketUser=root
SocketGroup=libvirt
RemoveOnStop=yes

[Install]
WantedBy=sockets.target
Also=libvirtd-ro.socket
Also=libvirtd-admin.socket
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/libvirtd-tcp.socket &lt;&lt; "EOF"
[Unit]
Description=libvirt legacy monolithic daemon non-TLS IP socket
BindsTo=libvirtd.socket
After=libvirtd.socket

[Socket]
ListenStream=16509
Service=libvirtd.service

[Install]
WantedBy=sockets.target
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/libvirtd.service &lt;&lt; "EOF"
[Unit]
Description=libvirt legacy monolithic daemon
Documentation=man:libvirtd(8)
Documentation=https://libvirt.org/
# Use Wants instead of Requires so that users
# can disable these three .socket units to revert
# to a traditional non-activation deployment setup
Wants=libvirtd.socket
Wants=libvirtd-ro.socket
Wants=libvirtd-admin.socket
After=libvirtd.socket
After=libvirtd-ro.socket
After=libvirtd-admin.socket
Requires=virtlogd.socket
Wants=virtlockd.socket
After=virtlogd.socket
After=virtlockd.socket
Wants=systemd-machined.service
After=network.target
After=dbus.service
After=iscsid.service
After=apparmor.service
After=remote-fs.target
After=systemd-machined.service
After=xencommons.service
After=qemu-kvm.service
Conflicts=xendomains.service

[Service]
Type=notify
Environment=LIBVIRTD_ARGS="--timeout 120"
EnvironmentFile=-/etc/default/libvirtd
ExecStart=/usr/sbin/libvirtd $LIBVIRTD_ARGS
ExecReload=/bin/kill -HUP $MAINPID
KillMode=process
Restart=on-failure
# Raise hard limits to match behaviour of systemd &lt;= 240.
# During startup, daemon will set soft limit to match hard limit
# per systemd recommendations
LimitNOFILE=1024:524288
# The cgroups pids controller can limit the number of tasks started by
# the daemon, which can limit the number of domains for some hypervisors.
# A conservative default of 8 tasks per guest results in a TasksMax of
# 32k to support 4096 guests.
TasksMax=32768
# With cgroups v2 there is no devices controller anymore, we have to use
# eBPF to control access to devices. In order to do that we create a eBPF
# hash MAP which locks memory. The default map size for 64 devices together
# with program takes 12k per guest. After rounding up we will get 64M to
# support 4096 guests.
LimitMEMLOCK=64M

[Install]
WantedBy=multi-user.target
Also=virtlockd.socket
Also=virtlogd.socket
Also=libvirtd.socket
Also=libvirtd-ro.socket
Also=libvirtd-admin.socket
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/virt-guest-shutdown.target &lt;&lt; "EOF"
[Unit]
Description=libvirt guests shutdown target
Documentation=https://libvirt.org/
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/virtlockd-admin.socket &lt;&lt; "EOF"
[Unit]
Description=libvirt locking daemon admin socket
BindsTo=virtlockd.socket
After=virtlockd.socket

[Socket]
ListenStream=/run/libvirt/virtlockd-admin-sock
Service=virtlockd.service
SocketMode=0600
RemoveOnStop=yes

[Install]
WantedBy=sockets.target
Also=virtlockd.socket
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/virtlockd.socket &lt;&lt; "EOF"
[Unit]
Description=libvirt locking daemon socket

[Socket]
ListenStream=/run/libvirt/virtlockd-sock
Service=virtlockd.service
SocketMode=0600
RemoveOnStop=yes

[Install]
WantedBy=sockets.target
Also=virtlockd-admin.socket
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/virtlogd-admin.socket &lt;&lt; "EOF"
[Unit]
Description=libvirt logging daemon admin socket
BindsTo=virtlogd.socket
After=virtlogd.socket

[Socket]
ListenStream=/run/libvirt/virtlogd-admin-sock
Service=virtlogd.service
SocketMode=0600
RemoveOnStop=yes

[Install]
WantedBy=sockets.target
Also=virtlogd.socket
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/libvirt-guests.service &lt;&lt; "EOF"
[Unit]
Description=libvirt guests suspend/resume service
Documentation=man:libvirt-guests(8)
Documentation=https://libvirt.org/
Requires=virt-guest-shutdown.target
After=network.target
After=time-sync.target
After=libvirtd.socket
After=virtqemud.socket
After=virtlxcd.socket
After=virtvboxd.socket
After=virtvzd.socket
After=virtxend.socket
After=virt-guest-shutdown.target

[Service]
EnvironmentFile=-/etc/default/libvirt-guests
# Hack just call traditional service until we factor
# out the code
ExecStart=/usr/lib/libvirt/libvirt-guests.sh start
ExecStop=/usr/lib/libvirt/libvirt-guests.sh stop
Type=oneshot
RemainAfterExit=yes
StandardOutput=journal+console
TimeoutStopSec=0

[Install]
WantedBy=multi-user.target
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/libvirtd-admin.socket &lt;&lt; "EOF"
[Unit]
Description=libvirt legacy monolithic daemon admin socket
BindsTo=libvirtd.socket
After=libvirtd.socket

[Socket]
ListenStream=/run/libvirt/libvirt-admin-sock
Service=libvirtd.service
SocketMode=0600
RemoveOnStop=yes

[Install]
WantedBy=sockets.target
Also=libvirtd.socket
Also=libvirtd-ro.socket
EOF</userinput></screen>

<screen role="root"><userinput>cat &gt; /usr/lib/systemd/system/virtlogd.socket &lt;&lt; "EOF"
[Unit]
Description=libvirt logging daemon socket

[Socket]
ListenStream=/run/libvirt/virtlogd-sock
Service=virtlogd.service
SocketMode=0600
RemoveOnStop=yes

[Install]
WantedBy=sockets.target
Also=virtlogd-admin.socket
EOF</userinput></screen>

<screen role="root"><userinput>chmod 0644 /etc/libvirt/*.conf &amp;&amp;
chmod 0644 /usr/lib/systemd/system/*virt* &amp;&amp;
install -v -m755 -d /etc/qemu &amp;&amp;
cat &gt; /etc/qemu/bridge.conf &lt;&lt; "EOF"
allow all
EOF</userinput></screen>
  </sect2>

  <sect2 role="content">
    <title>Contents</title>

    <segmentedlist>
      <segtitle>Installed Programs</segtitle>
      <segtitle>Installed Libraries</segtitle>
      <segtitle>Installed Directory</segtitle>

      <seglistitem>
	<seg>
          libvirt
        </seg>
        <seg>
          None
        </seg>
        <seg>
          /usr/share/libvirt
        </seg>
      </seglistitem>
    </segmentedlist>

  </sect2>

</sect1>